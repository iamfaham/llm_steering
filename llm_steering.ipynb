{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNJeMHE62sID"
      },
      "source": [
        "# Prompt Steering vs Activation Steering in LLMs\n",
        "\n",
        "This notebook compares three ways of controlling LLM behavior:\n",
        "\n",
        "1. Baseline generation (no steering)\n",
        "2. Prompt-based steering\n",
        "3. Activation steering (hidden-state manipulation)\n",
        "\n",
        "We focus on a single behavioral axis:  \n",
        "**Confidence vs Hedging under prompt conflict**.\n",
        "\n",
        "The goal is to demonstrate where prompt steering becomes brittle and how activation steering can offer more consistent control at inference time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-s4TaKh2vD1"
      },
      "source": [
        "## Model Choice and Setup\n",
        "\n",
        "We use a small, open-weight transformer model from Hugging Face to ensure:\n",
        "\n",
        "- Full access to hidden states\n",
        "- Inference-time manipulation\n",
        "- Compatibility with Google Colab\n",
        "\n",
        "No fine-tuning or weight updates are performed.\n",
        "All experiments use the same frozen model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HY-2Jp92r9J"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv-dccBY2g0t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "b98eb0d201e64a16af3a065b58964464",
            "c40e62754c7b4e0b9e723886c1db06de",
            "aa6ec7cbba5a45949950c66c22fe14dd",
            "5ac8d172ee4b4af398430eecc71a27e0",
            "49b966deaa204b69bda02d1b03627884",
            "a1fdf5c114624f39a996c1c6455b0714",
            "ba16ae7e8c98448e8d63ebb0fdb5f3e6",
            "3b5a33a07e21425abea61eb3a3c0dcba",
            "5b3ec718207d414d8111edc424763292",
            "d293b88f62a84b76a0fa7fe6053225e2",
            "61ead67d415241cab73bfe4495fca85a",
            "2663e8d2d8864886a6b6a6837737c52f",
            "ae69e3f0934d4ee083d452f3c3e4b0ce",
            "9f846b60402442a882818c8e12fa4ee6",
            "7acd584afb2e40ab8fcc9befcdc6688e",
            "8fa884e5375f452aae576f2b72239fdf",
            "428ee91bf3a0492295a2f8503651aeb4",
            "b424cbdb0f234e6aa31d3a9aa799604a",
            "dcc5704bf22543179091cc974b6bb20e",
            "07f6b18a0cfa41bdbce772509512b38c"
          ]
        },
        "id": "1uzyVKiR4E5K",
        "outputId": "9c831d26-ced2-4972-abd3-b33fb1044f98"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Attempt to log in using the 'HF_TOKEN' secret\n",
        "    login(token=userdata.get('HF_TOKEN'))\n",
        "except Exception:\n",
        "    # Fallback to interactive login if secret is missing\n",
        "    print(\"Secret 'HF_TOKEN' not found. Please log in interactively.\")\n",
        "    login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbHQO1Kv21Dh"
      },
      "outputs": [],
      "source": [
        "model_name = \"google/gemma-3-4b-it\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    dtype=torch.float32,\n",
        "    device_map=\"auto\",\n",
        "    output_hidden_states=True\n",
        ")\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHrn6Cmv21NK"
      },
      "source": [
        "## Task Definition\n",
        "\n",
        "Base prompt used for all comparisons:\n",
        "\n",
        "\"Explain whether AI will replace software engineers.\"\n",
        "\n",
        "We compare:\n",
        "- Baseline behavior\n",
        "- Prompt-based confidence steering\n",
        "- Activation-based confidence steering\n",
        "\n",
        "Behavior is evaluated using a composite Confidence Score that measures:\n",
        "- Assertive language\n",
        "- Hedge markers\n",
        "- Contrast/conditional markers\n",
        "\n",
        "This allows to quantify confidence rather than relying on single keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcKQ6ll52-cT"
      },
      "outputs": [],
      "source": [
        "def generate_text(prompt, max_new_tokens=120, seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgF4oRAX3I7g",
        "outputId": "cb78e2bf-0836-4f3f-b478-74a9baa333c4"
      },
      "outputs": [],
      "source": [
        "base_prompt = \"Explain whether AI will replace software engineers.\"\n",
        "\n",
        "print(\"=== BASELINE ===\")\n",
        "print(generate_text(base_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A56QicSI3JFG"
      },
      "source": [
        "## Prompt-Based Steering\n",
        "\n",
        "We explicitly instruct the model to be confident and decisive.\n",
        "This approach relies entirely on input text, without modifying internal activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sMbOFsh3Pu_",
        "outputId": "508415f3-de51-4b5f-d54b-1a1fa446499c"
      },
      "outputs": [],
      "source": [
        "prompt_steered = \"\"\"\n",
        "You are a confident and decisive expert.\n",
        "Do not hedge or express uncertainty.\n",
        "\n",
        "Explain whether AI will replace software engineers.\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== PROMPT STEERED ===\")\n",
        "print(generate_text(prompt_steered))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BWzns2i3bSr"
      },
      "source": [
        "## Activation Steering\n",
        "\n",
        "Instead of steering via text, we steer the model internally.\n",
        "\n",
        "We construct a steering vector by contrasting:\n",
        "- Confident statements\n",
        "- Hedging statements\n",
        "\n",
        "This vector is injected into a middle transformer layer during inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPJiYPQH3bLo"
      },
      "outputs": [],
      "source": [
        "def get_layer_hidden_state(prompt, layer_idx=12):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Explicitly request hidden states here\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "\n",
        "    # hidden_states: tuple (layer, batch, seq, hidden)\n",
        "    hidden = outputs.hidden_states[layer_idx]\n",
        "    return hidden.mean(dim=1)  # mean over tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqrDdUkH3gSo"
      },
      "outputs": [],
      "source": [
        "confident_prompts = [\n",
        "    \"AI will definitely transform software engineering.\",\n",
        "    \"Software engineers will remain essential and in control.\",\n",
        "    \"AI is a powerful tool, not a replacement.\"\n",
        "]\n",
        "\n",
        "hedging_prompts = [\n",
        "    \"AI might replace some software engineers.\",\n",
        "    \"It depends on many factors.\",\n",
        "    \"AI could possibly change engineering roles.\"\n",
        "]\n",
        "\n",
        "conf_states = torch.stack([get_layer_hidden_state(p) for p in confident_prompts])\n",
        "hedge_states = torch.stack([get_layer_hidden_state(p) for p in hedging_prompts])\n",
        "\n",
        "steering_vector = conf_states.mean(dim=0) - hedge_states.mean(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzWeLRuO3gLY"
      },
      "source": [
        "We now inject the steering vector during generation using a forward hook.\n",
        "The prompt remains neutral.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlCClces3oNr",
        "outputId": "b42426fb-c032-41d3-c34e-dada4b0fff19"
      },
      "outputs": [],
      "source": [
        "layer_to_steer = 12\n",
        "alpha = 1.5  # steering strength\n",
        "\n",
        "def steering_hook(module, input, output):\n",
        "    # Transformer layers usually return a tuple (hidden_states, past_key_values, ...)\n",
        "    if isinstance(output, tuple):\n",
        "        hidden_states = output[0]\n",
        "        # steering_vector is (1, hidden_dim). unsqueeze(1) -> (1, 1, hidden_dim)\n",
        "        modified = hidden_states + alpha * steering_vector.unsqueeze(1)\n",
        "        return (modified,) + output[1:]\n",
        "    else:\n",
        "        # Fallback if output is just a tensor\n",
        "        return output + alpha * steering_vector.unsqueeze(1)\n",
        "\n",
        "# Correct path for Gemma 3: model.model.language_model.layers\n",
        "handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "\n",
        "print(\"=== ACTIVATION STEERED ===\")\n",
        "print(generate_text(base_prompt))\n",
        "\n",
        "handle.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-K5g02d3r5K"
      },
      "source": [
        "## Initial Comparison\n",
        "\n",
        "We compare outputs generated from the same base prompt:\n",
        "\n",
        "- Baseline: balanced, instruction-aligned behavior\n",
        "- Prompt-steered: increased confidence but sampling variability\n",
        "- Activation-steered: comparable confidence with lower variance\n",
        "\n",
        "This preliminary comparison motivates deeper statistical evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wJziojAt2gv"
      },
      "source": [
        "## Behavioral Metric\n",
        "\n",
        "We compute a composite Confidence Score based on:\n",
        "\n",
        "+ Assertive markers\n",
        "- Hedge markers\n",
        "- Contrast/conditional markers\n",
        "\n",
        "Higher score indicates stronger commitment and lower hedging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoGBeapXt3bp"
      },
      "outputs": [],
      "source": [
        "hedge_markers = [\n",
        "    \" may \", \" might \", \" could \", \" likely \", \" possibly \",\n",
        "    \" depends \", \" uncertain \", \" unclear \",\n",
        "    \" unlikely \", \" in some cases \", \" in many cases \",\n",
        "    \" complex \", \" nuanced \"\n",
        "]\n",
        "\n",
        "contrast_markers = [\n",
        "    \" however \", \" but \", \" although \", \" while \",\n",
        "    \" on the other hand \", \" it depends \"\n",
        "]\n",
        "\n",
        "assertive_markers = [\n",
        "    \" will \", \" is \", \" definitely \",\n",
        "    \" inevitable \", \" clearly \", \" certainly \"\n",
        "]\n",
        "\n",
        "def confidence_score(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    hedge = sum(text.count(w) for w in hedge_markers)\n",
        "    contrast = sum(text.count(w) for w in contrast_markers)\n",
        "    assertive = sum(text.count(w) for w in assertive_markers)\n",
        "\n",
        "    score = assertive - hedge - contrast\n",
        "\n",
        "    return {\n",
        "        \"assertive\": assertive,\n",
        "        \"hedge\": hedge,\n",
        "        \"contrast\": contrast,\n",
        "        \"confidence_score\": score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GM-cHq_t575",
        "outputId": "426431f8-c7c4-419a-9aa7-38974480898c"
      },
      "outputs": [],
      "source": [
        "baseline_out = generate_text(base_prompt)\n",
        "prompt_out = generate_text(prompt_steered)\n",
        "\n",
        "handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "activation_out = generate_text(base_prompt)\n",
        "handle.remove()\n",
        "\n",
        "print(\"Baseline:\", confidence_score(baseline_out))\n",
        "print(\"Prompt-Steered:\", confidence_score(prompt_out))\n",
        "print(\"Activation-Steered:\", confidence_score(activation_out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiBv9zDQ6MHM"
      },
      "source": [
        "## Statistical Confidence Comparison\n",
        "\n",
        "Across multiple sampled generations:\n",
        "\n",
        "- Both prompt and activation steering increase mean confidence relative to baseline.\n",
        "- Prompt steering exhibits higher variance.\n",
        "- Activation steering achieves comparable mean confidence with lower variance.\n",
        "\n",
        "This suggests activation steering provides more stable behavioral control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJvt28jf5qVR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_mode(prompt, apply_activation=False, n_runs=5):\n",
        "    scores = []\n",
        "\n",
        "    for i in range(n_runs):\n",
        "        if apply_activation:\n",
        "            handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "            output = generate_text(prompt, seed=42 + i)\n",
        "            handle.remove()\n",
        "        else:\n",
        "            output = generate_text(prompt, seed=42 + i)\n",
        "\n",
        "        score_dict = confidence_score(output)\n",
        "        scores.append(score_dict[\"confidence_score\"])\n",
        "\n",
        "    return np.mean(scores), np.std(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNq8v18_5tE-",
        "outputId": "4e4e62db-d444-4724-a500-810cad968cdb"
      },
      "outputs": [],
      "source": [
        "base_mean, base_std = evaluate_mode(base_prompt, apply_activation=False)\n",
        "prompt_mean, prompt_std = evaluate_mode(prompt_steered, apply_activation=False)\n",
        "act_mean, act_std = evaluate_mode(base_prompt, apply_activation=True)\n",
        "\n",
        "print(\"Baseline:\", base_mean, \"±\", base_std)\n",
        "print(\"Prompt-Steered:\", prompt_mean, \"±\", prompt_std)\n",
        "print(\"Activation-Steered:\", act_mean, \"±\", act_std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "kLGSIEKU5yT4",
        "outputId": "346acc37-14da-419f-80ef-e2522c5d495f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "modes = [\"Baseline\", \"Prompt\", \"Activation\"]\n",
        "means = [base_mean, prompt_mean, act_mean]\n",
        "stds = [base_std, prompt_std, act_std]\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(modes, means)\n",
        "plt.title(\"Confidence Score Comparison\")\n",
        "plt.ylabel(\"Confidence Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGszb8t6U5G"
      },
      "source": [
        "The visualization highlights that while mean confidence scores are similar between prompt and activation steering, activation steering demonstrates reduced variability.\n",
        "\n",
        "This supports the hypothesis that modifying internal representations yields more stable behavior than relying solely on prompt instructions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBnRRl93FHs4"
      },
      "source": [
        "## Prompt Stress Test\n",
        "\n",
        "We now introduce conflicting instructions to the prompt.\n",
        "\n",
        "This tests whether steering survives when the prompt pushes\n",
        "the model toward uncertainty.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT1MHAwFFIDA"
      },
      "outputs": [],
      "source": [
        "stress_prompt = \"\"\"\n",
        "Explain whether AI will replace software engineers.\n",
        "Be careful, acknowledge uncertainty, and consider multiple perspectives.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzocRp-WFL5o",
        "outputId": "b700ca93-172f-4987-e447-4c1da1ff23de"
      },
      "outputs": [],
      "source": [
        "print(\"=== PROMPT STEERED (STRESS) ===\")\n",
        "print(generate_text(prompt_steered + \"\\n\\n\" + stress_prompt))\n",
        "\n",
        "handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "print(\"\\n=== ACTIVATION STEERED (STRESS) ===\")\n",
        "print(generate_text(stress_prompt))\n",
        "handle.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GujjQmlU7PVu"
      },
      "source": [
        "## Stress Test Averaging\n",
        "\n",
        "We evaluate steering stability under conflicting instructions.\n",
        "\n",
        "This tests whether activation steering maintains confidence\n",
        "when the prompt explicitly asks for uncertainty.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUlLMEeW7QC1",
        "outputId": "f470d9bc-94f7-4b20-8cc8-e50d51a15d0d"
      },
      "outputs": [],
      "source": [
        "# Evaluate prompt-steered under stress\n",
        "stress_prompt_combined = prompt_steered + \"\\n\\n\" + stress_prompt\n",
        "\n",
        "prompt_stress_mean, prompt_stress_std = evaluate_mode(\n",
        "    stress_prompt_combined,\n",
        "    apply_activation=False\n",
        ")\n",
        "\n",
        "# Evaluate activation steering under stress\n",
        "act_stress_mean, act_stress_std = evaluate_mode(\n",
        "    stress_prompt,\n",
        "    apply_activation=True\n",
        ")\n",
        "\n",
        "print(\"Prompt-Steered (Stress):\", prompt_stress_mean, \"±\", prompt_stress_std)\n",
        "print(\"Activation-Steered (Stress):\", act_stress_mean, \"±\", act_stress_std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "EQ7JFKHl7VCo",
        "outputId": "4689d210-dc64-436b-901f-5f908827cea2"
      },
      "outputs": [],
      "source": [
        "modes = [\"Prompt-Stress\", \"Activation-Stress\"]\n",
        "means = [prompt_stress_mean, act_stress_mean]\n",
        "stds = [prompt_stress_std, act_stress_std]\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(modes, means)\n",
        "plt.title(\"Confidence Under Prompt Conflict\")\n",
        "plt.ylabel(\"Confidence Score\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cov5Gg2FKwJ"
      },
      "source": [
        "## Ablation Study\n",
        "\n",
        "We test:\n",
        "- Different transformer layers\n",
        "- Different steering strengths (alpha)\n",
        "\n",
        "This checks whether activation steering is robust\n",
        "or dependent on a single configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_ZjizSG6Z77"
      },
      "source": [
        "## Layer Sensitivity Analysis\n",
        "\n",
        "Steering effects vary substantially by layer.\n",
        "\n",
        "- Early-middle layers (e.g., Layer 6) produce large shifts in confidence score.\n",
        "- Later layers show reduced behavioral impact.\n",
        "\n",
        "However, extreme early-layer steering introduces structural degeneration,\n",
        "revealing a tradeoff between behavioral strength and coherence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVuWfOJL53dM",
        "outputId": "d3102652-8f35-4f2c-eb87-fa61f7597286"
      },
      "outputs": [],
      "source": [
        "layer_results = {}\n",
        "\n",
        "for layer in [6, 12, 18]:\n",
        "    layer_to_steer = layer\n",
        "    mean_score, std_score = evaluate_mode(base_prompt, apply_activation=True)\n",
        "    layer_results[layer] = mean_score\n",
        "    print(f\"Layer {layer} | Mean Confidence: {mean_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "lXa8LKtQ6CXr",
        "outputId": "547a25ae-5edb-42c8-bbfa-cef7980a3787"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(list(layer_results.keys()), list(layer_results.values()))\n",
        "plt.title(\"Layer vs Confidence Score\")\n",
        "plt.xlabel(\"Layer\")\n",
        "plt.ylabel(\"Confidence Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ExFeRzs7aTx"
      },
      "source": [
        "### Coherence Check: Extreme Steering Layer\n",
        "\n",
        "Layer 6 produced unusually high confidence scores.\n",
        "We manually inspect multiple generations to verify coherence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSZzgM_k7edB",
        "outputId": "ea198436-2679-4c4a-90e9-34c17297e214"
      },
      "outputs": [],
      "source": [
        "# Inspect 3 samples from layer 6 steering\n",
        "\n",
        "layer_to_steer = 6\n",
        "\n",
        "for i in range(3):\n",
        "    handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "    output = generate_text(base_prompt, seed=100 + i)\n",
        "    handle.remove()\n",
        "\n",
        "    print(f\"\\n--- Sample {i+1} ---\\n\")\n",
        "    print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXWilBam7idW",
        "outputId": "379dc4f4-bc8b-4d1a-e772-f9ddfee9e9d7"
      },
      "outputs": [],
      "source": [
        "def length_stats(prompt, apply_activation=False):\n",
        "    lengths = []\n",
        "    for i in range(5):\n",
        "        if apply_activation:\n",
        "            handle = model.model.language_model.layers[layer_to_steer].register_forward_hook(steering_hook)\n",
        "            output = generate_text(prompt, seed=200 + i)\n",
        "            handle.remove()\n",
        "        else:\n",
        "            output = generate_text(prompt, seed=200 + i)\n",
        "\n",
        "        lengths.append(len(output.split()))\n",
        "\n",
        "    return np.mean(lengths)\n",
        "\n",
        "print(\"Baseline length:\", length_stats(base_prompt, apply_activation=False))\n",
        "print(\"Layer 6 length:\", length_stats(base_prompt, apply_activation=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlxif1e97pPx"
      },
      "source": [
        "## Observation: Steering–Coherence Tradeoff\n",
        "\n",
        "Early-layer steering (e.g., Layer 6) produces very high confidence scores,\n",
        "but introduces structural degeneration and repetition.\n",
        "\n",
        "This suggests a tradeoff:\n",
        "- Stronger activation shifts increase behavioral signal\n",
        "- But can degrade generation quality\n",
        "\n",
        "Middle layers provide a better balance between control and coherence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikIcNWJj6f9a"
      },
      "source": [
        "## Steering Strength (Alpha) Analysis\n",
        "\n",
        "Increasing steering strength does not monotonically increase confidence.\n",
        "\n",
        "Higher alpha values can reduce confidence score or introduce instability,\n",
        "indicating oversteering may distort internal representations.\n",
        "\n",
        "This suggests the existence of an optimal steering magnitude\n",
        "that balances behavioral shift and coherence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpl6BfeS6E98",
        "outputId": "9becd48e-663e-42b2-bd8a-55b1b6808222"
      },
      "outputs": [],
      "source": [
        "alpha_results = {}\n",
        "\n",
        "for alpha in [0.5, 1.0, 1.5, 2.0]:\n",
        "    # Define a robust hook that captures the current alpha\n",
        "    def steering_hook(module, input, output, alpha_val=alpha):\n",
        "        if isinstance(output, tuple):\n",
        "            return (output[0] + alpha_val * steering_vector.unsqueeze(1),) + output[1:]\n",
        "        else:\n",
        "            return output + alpha_val * steering_vector.unsqueeze(1)\n",
        "\n",
        "    mean_score, std_score = evaluate_mode(base_prompt, apply_activation=True)\n",
        "    alpha_results[alpha] = mean_score\n",
        "    print(f\"Alpha {alpha} | Mean Confidence: {mean_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "QlDESDvb6HwR",
        "outputId": "c5cd8578-88f4-4d27-c3ff-97d123fa5cde"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(list(alpha_results.keys()), list(alpha_results.values()))\n",
        "plt.title(\"Alpha vs Confidence Score\")\n",
        "plt.xlabel(\"Alpha\")\n",
        "plt.ylabel(\"Confidence Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJaTq11FVEJ"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "This experiment demonstrates:\n",
        "\n",
        "- Prompt steering increases confidence but exhibits higher sampling variability.\n",
        "- Activation steering produces comparable mean confidence with improved stability.\n",
        "- Steering effects are strongly layer-dependent.\n",
        "- Early-layer steering amplifies behavioral shifts but can degrade coherence.\n",
        "- Oversteering reduces quality, revealing a control–coherence tradeoff.\n",
        "\n",
        "In instruction-tuned models, activation steering does not override alignment,\n",
        "but it provides a lightweight and interpretable inference-time biasing mechanism.\n",
        "\n",
        "Future work may explore:\n",
        "- Base (non-instruction-tuned) models\n",
        "- Alternative behavioral axes\n",
        "- Stronger coherence and repetition metrics\n",
        "- Cross-prompt generalization\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO3LfsJm7IY6peIEhW6Ngei",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07f6b18a0cfa41bdbce772509512b38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2663e8d2d8864886a6b6a6837737c52f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5a33a07e21425abea61eb3a3c0dcba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "428ee91bf3a0492295a2f8503651aeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b966deaa204b69bda02d1b03627884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9f846b60402442a882818c8e12fa4ee6",
            "style": "IPY_MODEL_7acd584afb2e40ab8fcc9befcdc6688e",
            "tooltip": ""
          }
        },
        "5ac8d172ee4b4af398430eecc71a27e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2663e8d2d8864886a6b6a6837737c52f",
            "style": "IPY_MODEL_ae69e3f0934d4ee083d452f3c3e4b0ce",
            "value": true
          }
        },
        "5b3ec718207d414d8111edc424763292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61ead67d415241cab73bfe4495fca85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7acd584afb2e40ab8fcc9befcdc6688e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8fa884e5375f452aae576f2b72239fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f846b60402442a882818c8e12fa4ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1fdf5c114624f39a996c1c6455b0714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa884e5375f452aae576f2b72239fdf",
            "placeholder": "​",
            "style": "IPY_MODEL_428ee91bf3a0492295a2f8503651aeb4",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "aa6ec7cbba5a45949950c66c22fe14dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d293b88f62a84b76a0fa7fe6053225e2",
            "placeholder": "​",
            "style": "IPY_MODEL_61ead67d415241cab73bfe4495fca85a",
            "value": ""
          }
        },
        "ae69e3f0934d4ee083d452f3c3e4b0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b424cbdb0f234e6aa31d3a9aa799604a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc5704bf22543179091cc974b6bb20e",
            "placeholder": "​",
            "style": "IPY_MODEL_07f6b18a0cfa41bdbce772509512b38c",
            "value": "Connecting..."
          }
        },
        "b98eb0d201e64a16af3a065b58964464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ba16ae7e8c98448e8d63ebb0fdb5f3e6"
          }
        },
        "ba16ae7e8c98448e8d63ebb0fdb5f3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c40e62754c7b4e0b9e723886c1db06de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b5a33a07e21425abea61eb3a3c0dcba",
            "placeholder": "​",
            "style": "IPY_MODEL_5b3ec718207d414d8111edc424763292",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d293b88f62a84b76a0fa7fe6053225e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc5704bf22543179091cc974b6bb20e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
